% !TeX encoding = UTF-8
% !TeX root = MAIN.tex

@book{molnar2022,
	title      = {Interpretable Machine Learning},
	author     = {Christoph Molnar},
	year       = {2022},
	subtitle   = {A Guide for Making Black Box Models Explainable},
	edition    = {2},
	url        = {https://christophm.github.io/interpretable-ml-book}
}

@misc{PDP,
	title={A Simple and Effective Model-Based Variable Importance Measure}, 
	author={Brandon M. Greenwell and Bradley C. Boehmke and Andrew J. McCarthy},
	year={2018},
	eprint={1805.04755},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}
@misc{apley2019visualizing,
	title={Visualizing the Effects of Predictor Variables in Black Box Supervised Learning Models}, 
	author={Daniel W. Apley and Jingyu Zhu},
	year={2019},
	eprint={1612.08468},
	archivePrefix={arXiv},
	primaryClass={stat.ME}
}

@misc{inglis2021visualizing,
	title={Visualizing Variable Importance and Variable Interaction Effects in Machine Learning Models}, 
	author={Alan Inglis and Andrew Parnell and Catherine Hurley},
	year={2021},
	eprint={2108.04310},
	archivePrefix={arXiv},
	primaryClass={stat.CO}
}

@inproceedings{FA1,
	author = {Hooker, Giles},
	year = {2004},
	month = {08},
	pages = {575-580},
	title = {Discovering additive structure in black box functions},
	journal = {KDD-2004 - Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	doi = {10.1145/1014052.1014122}
}

@article{FA2,
	title={Generalized Functional ANOVA Diagnostics for High-Dimensional Functions of Dependent Variables},
	author={Giles Hooker},
	journal={Journal of Computational and Graphical Statistics},
	year={2007},
	volume={16},
	pages={709 - 732},
	url={https://api.semanticscholar.org/CorpusID:10727333}
}
@misc{fisher2019models,
	title={All Models are Wrong, but Many are Useful: Learning a Variable's Importance by Studying an Entire Class of Prediction Models Simultaneously}, 
	author={Aaron Fisher and Cynthia Rudin and Francesca Dominici},
	year={2019},
	eprint={1801.01489},
	archivePrefix={arXiv},
	primaryClass={stat.ME}
}


@article{pac,
	title = "Examples are not enough, learn to criticize! Criticism for interpretability",
	abstract = "Example-based explanations are widely used in the effort to improve the interpretability of highly complex distributions. However, prototypes alone are rarely sufficient to represent the GIST of the complexity. In order for users to construct better mental models and understand complex data distributions, we also need criticism to explain what are not captured by prototypes. Motivated by the Bayesian model criticism framework, we develop MMD-critic which efficiently learns prototypes and criticism, designed to aid human interpretability. A human subject pilot study shows that the MMD-critic selects prototypes and criticism that are useful to facilitate human understanding and reasoning. We also evaluate the prototypes selected by MMD-critic via a nearest prototype classifier, showing competitive performance compared to baselines.",
	author = "Been Kim and Rajiv Khanna and Oluwasanmi Koyejo",
	year = "2016",
	language = "English (US)",
	pages = "2288--2296",
	journal = "Advances in Neural Information Processing Systems",
	issn = "1049-5258",
	note = "30th Annual Conference on Neural Information Processing Systems, NIPS 2016 ; Conference date: 05-12-2016 Through 10-12-2016",
}

@misc{adebayo2020sanity,
	title={Sanity Checks for Saliency Maps}, 
	author={Julius Adebayo and Justin Gilmer and Michael Muelly and Ian Goodfellow and Moritz Hardt and Been Kim},
	year={2020},
	eprint={1810.03292},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@misc{hooker2019benchmark,
	title={A Benchmark for Interpretability Methods in Deep Neural Networks}, 
	author={Sara Hooker and Dumitru Erhan and Pieter-Jan Kindermans and Been Kim},
	year={2019},
	eprint={1806.10758},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@misc{gupta2022new,
	title={New Definitions and Evaluations for Saliency Methods: Staying Intrinsic, Complete and Sound}, 
	author={Arushi Gupta and Nikunj Saunshi and Dingli Yu and Kaifeng Lyu and Sanjeev Arora},
	year={2022},
	eprint={2211.02912},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}

@inproceedings{bossard14,
	title = {Food-101 -- Mining Discriminative Components with Random Forests},
	author = {Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},
	booktitle = {European Conference on Computer Vision},
	year = {2014}
}

@article{article,
	author = {Zhang, Jianming and Bargal, Sarah and Lin, Zhe and Brandt, Jonathan and Shen, Xiaohui and Sclaroff, Stan},
	year = {2018},
	month = {10},
	pages = {},
	title = {Top-Down Neural Attention by Excitation Backprop},
	volume = {126},
	journal = {International Journal of Computer Vision},
	doi = {10.1007/s11263-017-1059-x}
}

@misc{petsiuk2018rise,
	title={RISE: Randomized Input Sampling for Explanation of Black-box Models}, 
	author={Vitali Petsiuk and Abir Das and Kate Saenko},
	year={2018},
	eprint={1806.07421},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@ARTICLE{7552539,
	author={Samek, Wojciech and Binder, Alexander and Montavon, Grégoire and Lapuschkin, Sebastian and Müller, Klaus-Robert},
	journal={IEEE Transactions on Neural Networks and Learning Systems}, 
	title={Evaluating the Visualization of What a Deep Neural Network Has Learned}, 
	year={2017},
	volume={28},
	number={11},
	pages={2660-2673},
	doi={10.1109/TNNLS.2016.2599820}
}

@misc{yang2019benchmarking,
	title={Benchmarking Attribution Methods with Relative Feature Importance}, 
	author={Mengjiao Yang and Been Kim},
	year={2019},
	eprint={1907.09701},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@misc{lin2015microsoft,
	title={Microsoft COCO: Common Objects in Context}, 
	author={Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
	year={2015},
	eprint={1405.0312},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@misc{petsiuk2018rise,
	title={RISE: Randomized Input Sampling for Explanation of Black-box Models}, 
	author={Vitali Petsiuk and Abir Das and Kate Saenko},
	year={2018},
	eprint={1806.07421},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@misc{dabkowski2017real,
	title={Real Time Image Saliency for Black Box Classifiers}, 
	author={Piotr Dabkowski and Yarin Gal},
	year={2017},
	eprint={1705.07857},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}

@article{olah2017feature,
	author = {Olah, Chris and Mordvintsev, Alexander and Schubert, Ludwig},
	title = {Feature Visualization},
	journal = {Distill},
	year = {2017},
	note = {https://distill.pub/2017/feature-visualization},
	doi = {10.23915/distill.00007}
}

@inproceedings{bossard14,
	title = {Food-101 -- Mining Discriminative Components with Random Forests},
	author = {Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},
	booktitle = {European Conference on Computer Vision},
	year = {2014}
}

@article{deng2012mnist,
	title={The mnist database of handwritten digit images for machine learning research},
	author={Deng, Li},
	journal={IEEE Signal Processing Magazine},
	volume={29},
	number={6},
	pages={141--142},
	year={2012},
	publisher={IEEE}
} 

@misc{lundberg2017unified,
	title={A Unified Approach to Interpreting Model Predictions}, 
	author={Scott Lundberg and Su-In Lee},
	year={2017},
	eprint={1705.07874},
	archivePrefix={arXiv},
	primaryClass={cs.AI}
}

@misc{simonyan2014deep,
	title={Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps}, 
	author={Karen Simonyan and Andrea Vedaldi and Andrew Zisserman},
	year={2014},
	eprint={1312.6034},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@misc{zeiler2013visualizing,
	title={Visualizing and Understanding Convolutional Networks}, 
	author={Matthew D Zeiler and Rob Fergus},
	year={2013},
	eprint={1311.2901},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@article{krizhevsky2012,
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	title = {ImageNet Classification with Deep Convolutional Neural Networks},
	year = {2017},
	issue_date = {June 2017},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {60},
	number = {6},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/3065386},
	doi = {10.1145/3065386},
	abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.},
	journal = {Commun. ACM},
	month = {may},
	pages = {84–90},
	numpages = {7}
}


